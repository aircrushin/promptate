{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OTJK9gzv7-aF"
      },
      "source": [
        "# add dependencies"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xPZOP_Kf8_XU",
        "outputId": "d58755df-5e8c-4fd0-a064-d7a258c50b96"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: datasets in e:\\baidunetdiskdownload\\chatglm3\\glut\\lib\\site-packages (2.17.1)\n",
            "Requirement already satisfied: tiktoken in e:\\baidunetdiskdownload\\chatglm3\\glut\\lib\\site-packages (0.6.0)\n",
            "Requirement already satisfied: openai in e:\\baidunetdiskdownload\\chatglm3\\glut\\lib\\site-packages (1.3.3)\n",
            "Requirement already satisfied: filelock in e:\\baidunetdiskdownload\\chatglm3\\glut\\lib\\site-packages (from datasets) (3.9.0)\n",
            "Requirement already satisfied: numpy>=1.17 in e:\\baidunetdiskdownload\\chatglm3\\glut\\lib\\site-packages (from datasets) (1.24.1)\n",
            "Requirement already satisfied: pyarrow>=12.0.0 in e:\\baidunetdiskdownload\\chatglm3\\glut\\lib\\site-packages (from datasets) (13.0.0)\n",
            "Requirement already satisfied: pyarrow-hotfix in e:\\baidunetdiskdownload\\chatglm3\\glut\\lib\\site-packages (from datasets) (0.6)\n",
            "Requirement already satisfied: dill<0.3.9,>=0.3.0 in e:\\baidunetdiskdownload\\chatglm3\\glut\\lib\\site-packages (from datasets) (0.3.8)\n",
            "Requirement already satisfied: pandas in e:\\baidunetdiskdownload\\chatglm3\\glut\\lib\\site-packages (from datasets) (2.1.2)\n",
            "Requirement already satisfied: requests>=2.19.0 in e:\\baidunetdiskdownload\\chatglm3\\glut\\lib\\site-packages (from datasets) (2.31.0)\n",
            "Requirement already satisfied: tqdm>=4.62.1 in e:\\baidunetdiskdownload\\chatglm3\\glut\\lib\\site-packages (from datasets) (4.66.1)\n",
            "Requirement already satisfied: xxhash in e:\\baidunetdiskdownload\\chatglm3\\glut\\lib\\site-packages (from datasets) (3.4.1)\n",
            "Requirement already satisfied: multiprocess in e:\\baidunetdiskdownload\\chatglm3\\glut\\lib\\site-packages (from datasets) (0.70.16)\n",
            "Requirement already satisfied: fsspec<=2023.10.0,>=2023.1.0 in e:\\baidunetdiskdownload\\chatglm3\\glut\\lib\\site-packages (from fsspec[http]<=2023.10.0,>=2023.1.0->datasets) (2023.10.0)\n",
            "Requirement already satisfied: aiohttp in e:\\baidunetdiskdownload\\chatglm3\\glut\\lib\\site-packages (from datasets) (3.8.6)\n",
            "Requirement already satisfied: huggingface-hub>=0.19.4 in e:\\baidunetdiskdownload\\chatglm3\\glut\\lib\\site-packages (from datasets) (0.19.4)\n",
            "Requirement already satisfied: packaging in e:\\baidunetdiskdownload\\chatglm3\\glut\\lib\\site-packages (from datasets) (23.2)\n",
            "Requirement already satisfied: pyyaml>=5.1 in e:\\baidunetdiskdownload\\chatglm3\\glut\\lib\\site-packages (from datasets) (6.0.1)\n",
            "Requirement already satisfied: regex>=2022.1.18 in e:\\baidunetdiskdownload\\chatglm3\\glut\\lib\\site-packages (from tiktoken) (2023.10.3)\n",
            "Requirement already satisfied: anyio<4,>=3.5.0 in e:\\baidunetdiskdownload\\chatglm3\\glut\\lib\\site-packages (from openai) (3.7.1)\n",
            "Requirement already satisfied: distro<2,>=1.7.0 in e:\\baidunetdiskdownload\\chatglm3\\glut\\lib\\site-packages (from openai) (1.8.0)\n",
            "Requirement already satisfied: httpx<1,>=0.23.0 in e:\\baidunetdiskdownload\\chatglm3\\glut\\lib\\site-packages (from openai) (0.25.0)\n",
            "Requirement already satisfied: pydantic<3,>=1.9.0 in e:\\baidunetdiskdownload\\chatglm3\\glut\\lib\\site-packages (from openai) (2.5.1)\n",
            "Requirement already satisfied: typing-extensions<5,>=4.5 in e:\\baidunetdiskdownload\\chatglm3\\glut\\lib\\site-packages (from openai) (4.8.0)\n",
            "Requirement already satisfied: idna>=2.8 in e:\\baidunetdiskdownload\\chatglm3\\glut\\lib\\site-packages (from anyio<4,>=3.5.0->openai) (3.4)\n",
            "Requirement already satisfied: sniffio>=1.1 in e:\\baidunetdiskdownload\\chatglm3\\glut\\lib\\site-packages (from anyio<4,>=3.5.0->openai) (1.3.0)\n",
            "Requirement already satisfied: exceptiongroup in e:\\baidunetdiskdownload\\chatglm3\\glut\\lib\\site-packages (from anyio<4,>=3.5.0->openai) (1.1.3)\n",
            "Requirement already satisfied: attrs>=17.3.0 in e:\\baidunetdiskdownload\\chatglm3\\glut\\lib\\site-packages (from aiohttp->datasets) (23.1.0)\n",
            "Requirement already satisfied: charset-normalizer<4.0,>=2.0 in e:\\baidunetdiskdownload\\chatglm3\\glut\\lib\\site-packages (from aiohttp->datasets) (2.1.1)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in e:\\baidunetdiskdownload\\chatglm3\\glut\\lib\\site-packages (from aiohttp->datasets) (6.0.4)\n",
            "Requirement already satisfied: async-timeout<5.0,>=4.0.0a3 in e:\\baidunetdiskdownload\\chatglm3\\glut\\lib\\site-packages (from aiohttp->datasets) (4.0.3)\n",
            "Requirement already satisfied: yarl<2.0,>=1.0 in e:\\baidunetdiskdownload\\chatglm3\\glut\\lib\\site-packages (from aiohttp->datasets) (1.9.2)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in e:\\baidunetdiskdownload\\chatglm3\\glut\\lib\\site-packages (from aiohttp->datasets) (1.4.0)\n",
            "Requirement already satisfied: aiosignal>=1.1.2 in e:\\baidunetdiskdownload\\chatglm3\\glut\\lib\\site-packages (from aiohttp->datasets) (1.3.1)\n",
            "Requirement already satisfied: certifi in e:\\baidunetdiskdownload\\chatglm3\\glut\\lib\\site-packages (from httpx<1,>=0.23.0->openai) (2022.12.7)\n",
            "Requirement already satisfied: httpcore<0.19.0,>=0.18.0 in e:\\baidunetdiskdownload\\chatglm3\\glut\\lib\\site-packages (from httpx<1,>=0.23.0->openai) (0.18.0)\n",
            "Requirement already satisfied: annotated-types>=0.4.0 in e:\\baidunetdiskdownload\\chatglm3\\glut\\lib\\site-packages (from pydantic<3,>=1.9.0->openai) (0.6.0)\n",
            "Requirement already satisfied: pydantic-core==2.14.3 in e:\\baidunetdiskdownload\\chatglm3\\glut\\lib\\site-packages (from pydantic<3,>=1.9.0->openai) (2.14.3)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in e:\\baidunetdiskdownload\\chatglm3\\glut\\lib\\site-packages (from requests>=2.19.0->datasets) (1.26.13)\n",
            "Requirement already satisfied: colorama in e:\\baidunetdiskdownload\\chatglm3\\glut\\lib\\site-packages (from tqdm>=4.62.1->datasets) (0.4.6)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in e:\\baidunetdiskdownload\\chatglm3\\glut\\lib\\site-packages (from pandas->datasets) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in e:\\baidunetdiskdownload\\chatglm3\\glut\\lib\\site-packages (from pandas->datasets) (2023.3.post1)\n",
            "Requirement already satisfied: tzdata>=2022.1 in e:\\baidunetdiskdownload\\chatglm3\\glut\\lib\\site-packages (from pandas->datasets) (2023.3)\n",
            "Requirement already satisfied: h11<0.15,>=0.13 in e:\\baidunetdiskdownload\\chatglm3\\glut\\lib\\site-packages (from httpcore<0.19.0,>=0.18.0->httpx<1,>=0.23.0->openai) (0.14.0)\n",
            "Requirement already satisfied: six>=1.5 in e:\\baidunetdiskdownload\\chatglm3\\glut\\lib\\site-packages (from python-dateutil>=2.8.2->pandas->datasets) (1.16.0)\n",
            "Note: you may need to restart the kernel to use updated packages.\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n",
            "[notice] A new release of pip is available: 23.3.1 -> 24.0\n",
            "[notice] To update, run: python.exe -m pip install --upgrade pip\n"
          ]
        }
      ],
      "source": [
        "%pip install datasets tiktoken openai"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FFD-Kyp09fq0",
        "outputId": "88608d1e-491c-40e4-951b-af5ad7896de3"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: numpy in e:\\baidunetdiskdownload\\chatglm3\\glut\\lib\\site-packages (1.24.1)\n",
            "Requirement already satisfied: pandas in e:\\baidunetdiskdownload\\chatglm3\\glut\\lib\\site-packages (2.1.2)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in e:\\baidunetdiskdownload\\chatglm3\\glut\\lib\\site-packages (from pandas) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in e:\\baidunetdiskdownload\\chatglm3\\glut\\lib\\site-packages (from pandas) (2023.3.post1)\n",
            "Requirement already satisfied: tzdata>=2022.1 in e:\\baidunetdiskdownload\\chatglm3\\glut\\lib\\site-packages (from pandas) (2023.3)\n",
            "Requirement already satisfied: six>=1.5 in e:\\baidunetdiskdownload\\chatglm3\\glut\\lib\\site-packages (from python-dateutil>=2.8.2->pandas) (1.16.0)\n",
            "Note: you may need to restart the kernel to use updated packages.\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n",
            "[notice] A new release of pip is available: 23.3.1 -> 24.0\n",
            "[notice] To update, run: python.exe -m pip install --upgrade pip\n"
          ]
        }
      ],
      "source": [
        "%pip install numpy pandas"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 数据准备"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {},
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "df = pd.read_csv(\"./content/prompts.csv\")\n",
        "\n",
        "import json\n",
        "\n",
        "# Convert dataframe to JSONL format\n",
        "jsonl_lines = []\n",
        "for _, row in df.iterrows():\n",
        "    # Construct the JSON object for each row\n",
        "    json_obj = {\n",
        "        \"messages\": [\n",
        "            {\"role\": \"system\", \"content\": f\"you are a strong and helpful assistant to create prompt from a single or several words\"},\n",
        "            {\"role\": \"user\", \"content\": row['act']},\n",
        "            {\"role\": \"assistant\", \"content\": row['prompt']}\n",
        "        ]\n",
        "    }\n",
        "    jsonl_lines.append(json.dumps(json_obj))\n",
        "\n",
        "# Save the JSONL lines to a file\n",
        "jsonl_file_path = './content/full_data.jsonl'\n",
        "with open(jsonl_file_path, 'w') as jsonl_file:\n",
        "    for line in jsonl_lines:\n",
        "        jsonl_file.write(line + '\\n')\n",
        "\n",
        "jsonl_file_path"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "H9Cd-wePDHK2"
      },
      "source": [
        "# 探索数据和花费"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xGEVodWv9K2k",
        "outputId": "54d34d7a-e578-4dc1-9a23-a2a281d9176a"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Num examples: 131\n",
            "First example:\n",
            "{'role': 'system', 'content': 'you are a strong and helpful assistant to create prompt from a single or several words'}\n",
            "{'role': 'user', 'content': 'Linux Terminal'}\n",
            "{'role': 'assistant', 'content': 'I want you to act as a linux terminal. I will type commands and you will reply with what the terminal should show. I want you to only reply with the terminal output inside one unique code block, and nothing else. do not write explanations. do not type commands unless I instruct you to do so. when i need to tell you something in english, i will do so by putting text inside curly brackets {like this}. my first command is pwd'}\n"
          ]
        }
      ],
      "source": [
        "import json\n",
        "import tiktoken # for token counting\n",
        "import numpy as np\n",
        "from collections import defaultdict\n",
        "\n",
        "data_path = \"./content/training_data.jsonl\"\n",
        "\n",
        "# Load the dataset\n",
        "with open(data_path, 'r', encoding='utf-8') as f:\n",
        "    dataset = [json.loads(line) for line in f]\n",
        "\n",
        "# Initial dataset stats\n",
        "print(\"Num examples:\", len(dataset))\n",
        "print(\"First example:\")\n",
        "for message in dataset[0][\"messages\"]:\n",
        "    print(message)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "scl0xzENAPQd",
        "outputId": "63f4ca45-6c59-4b06-9e0a-39b0a91a17b5"
      },
      "outputs": [
        {
          "ename": "",
          "evalue": "",
          "output_type": "error",
          "traceback": [
            "\u001b[1;31m运行具有“c:\\Users\\Administrator\\AppData\\Local\\Programs\\Python\\Python310-32\\python.exe”的单元格需要ipykernel包。\n",
            "\u001b[1;31mRun the following command to install 'ipykernel' into the Python environment. \n",
            "\u001b[1;31mCommand: 'c:/Users/Administrator/AppData/Local/Programs/Python/Python310-32/python.exe -m pip install ipykernel -U --user --force-reinstall'"
          ]
        }
      ],
      "source": [
        "# Format error checks\n",
        "format_errors = defaultdict(int)\n",
        "\n",
        "for ex in dataset:\n",
        "    if not isinstance(ex, dict):\n",
        "        format_errors[\"data_type\"] += 1\n",
        "        continue\n",
        "\n",
        "    messages = ex.get(\"messages\", None)\n",
        "    if not messages:\n",
        "        format_errors[\"missing_messages_list\"] += 1\n",
        "        continue\n",
        "\n",
        "    for message in messages:\n",
        "        if \"role\" not in message or \"content\" not in message:\n",
        "            format_errors[\"message_missing_key\"] += 1\n",
        "\n",
        "        if any(k not in (\"role\", \"content\", \"name\", \"function_call\") for k in message):\n",
        "            format_errors[\"message_unrecognized_key\"] += 1\n",
        "\n",
        "        if message.get(\"role\", None) not in (\"system\", \"user\", \"assistant\", \"function\"):\n",
        "            format_errors[\"unrecognized_role\"] += 1\n",
        "\n",
        "        content = message.get(\"content\", None)\n",
        "        function_call = message.get(\"function_call\", None)\n",
        "\n",
        "        if (not content and not function_call) or not isinstance(content, str):\n",
        "            format_errors[\"missing_content\"] += 1\n",
        "\n",
        "    if not any(message.get(\"role\", None) == \"assistant\" for message in messages):\n",
        "        format_errors[\"example_missing_assistant_message\"] += 1\n",
        "\n",
        "if format_errors:\n",
        "    print(\"Found errors:\")\n",
        "    for k, v in format_errors.items():\n",
        "        print(f\"{k}: {v}\")\n",
        "else:\n",
        "    print(\"No errors found\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ML94XaJ6AWXV"
      },
      "outputs": [
        {
          "ename": "",
          "evalue": "",
          "output_type": "error",
          "traceback": [
            "\u001b[1;31m运行具有“c:\\Users\\Administrator\\AppData\\Local\\Programs\\Python\\Python310-32\\python.exe”的单元格需要ipykernel包。\n",
            "\u001b[1;31mRun the following command to install 'ipykernel' into the Python environment. \n",
            "\u001b[1;31mCommand: 'c:/Users/Administrator/AppData/Local/Programs/Python/Python310-32/python.exe -m pip install ipykernel -U --user --force-reinstall'"
          ]
        }
      ],
      "source": [
        "encoding = tiktoken.get_encoding(\"cl100k_base\")\n",
        "\n",
        "# not exact!\n",
        "# simplified from https://github.com/openai/openai-cookbook/blob/main/examples/How_to_count_tokens_with_tiktoken.ipynb\n",
        "def num_tokens_from_messages(messages, tokens_per_message=3, tokens_per_name=1):\n",
        "    num_tokens = 0\n",
        "    for message in messages:\n",
        "        num_tokens += tokens_per_message\n",
        "        for key, value in message.items():\n",
        "            num_tokens += len(encoding.encode(value))\n",
        "            if key == \"name\":\n",
        "                num_tokens += tokens_per_name\n",
        "    num_tokens += 3\n",
        "    return num_tokens\n",
        "\n",
        "def num_assistant_tokens_from_messages(messages):\n",
        "    num_tokens = 0\n",
        "    for message in messages:\n",
        "        if message[\"role\"] == \"assistant\":\n",
        "            num_tokens += len(encoding.encode(message[\"content\"]))\n",
        "    return num_tokens\n",
        "\n",
        "def print_distribution(values, name):\n",
        "    print(f\"\\n#### Distribution of {name}:\")\n",
        "    print(f\"min / max: {min(values)}, {max(values)}\")\n",
        "    print(f\"mean / median: {np.mean(values)}, {np.median(values)}\")\n",
        "    print(f\"p5 / p95: {np.quantile(values, 0.1)}, {np.quantile(values, 0.9)}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 计算token数量"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fpkjfmaDAdkG",
        "outputId": "bbbb40b7-00ef-4f89-b91e-9f5faa30bd00"
      },
      "outputs": [
        {
          "ename": "",
          "evalue": "",
          "output_type": "error",
          "traceback": [
            "\u001b[1;31m运行具有“c:\\Users\\Administrator\\AppData\\Local\\Programs\\Python\\Python310-32\\python.exe”的单元格需要ipykernel包。\n",
            "\u001b[1;31mRun the following command to install 'ipykernel' into the Python environment. \n",
            "\u001b[1;31mCommand: 'c:/Users/Administrator/AppData/Local/Programs/Python/Python310-32/python.exe -m pip install ipykernel -U --user --force-reinstall'"
          ]
        }
      ],
      "source": [
        "# Warnings and tokens counts\n",
        "n_missing_system = 0\n",
        "n_missing_user = 0\n",
        "n_messages = []\n",
        "convo_lens = []\n",
        "assistant_message_lens = []\n",
        "\n",
        "for ex in dataset:\n",
        "    messages = ex[\"messages\"]\n",
        "    if not any(message[\"role\"] == \"system\" for message in messages):\n",
        "        n_missing_system += 1\n",
        "    if not any(message[\"role\"] == \"user\" for message in messages):\n",
        "        n_missing_user += 1\n",
        "    n_messages.append(len(messages))\n",
        "    convo_lens.append(num_tokens_from_messages(messages))\n",
        "    assistant_message_lens.append(num_assistant_tokens_from_messages(messages))\n",
        "\n",
        "print(\"Num examples missing system message:\", n_missing_system)\n",
        "print(\"Num examples missing user message:\", n_missing_user)\n",
        "print_distribution(n_messages, \"num_messages_per_example\")\n",
        "print_distribution(convo_lens, \"num_total_tokens_per_example\")\n",
        "print_distribution(assistant_message_lens, \"num_assistant_tokens_per_example\")\n",
        "n_too_long = sum(l > 4096 for l in convo_lens)\n",
        "print(f\"\\n{n_too_long} examples may be over the 4096 token limit, they will be truncated during fine-tuning\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NrgeL6PSAwaE",
        "outputId": "cd493679-bcf5-48d2-872c-69a171493f3e"
      },
      "outputs": [
        {
          "ename": "",
          "evalue": "",
          "output_type": "error",
          "traceback": [
            "\u001b[1;31m运行具有“c:\\Users\\Administrator\\AppData\\Local\\Programs\\Python\\Python310-32\\python.exe”的单元格需要ipykernel包。\n",
            "\u001b[1;31mRun the following command to install 'ipykernel' into the Python environment. \n",
            "\u001b[1;31mCommand: 'c:/Users/Administrator/AppData/Local/Programs/Python/Python310-32/python.exe -m pip install ipykernel -U --user --force-reinstall'"
          ]
        }
      ],
      "source": [
        "# Pricing and default n_epochs estimate\n",
        "MAX_TOKENS_PER_EXAMPLE = 4096\n",
        "\n",
        "TARGET_EPOCHS = 3\n",
        "MIN_TARGET_EXAMPLES = 100\n",
        "MAX_TARGET_EXAMPLES = 25000\n",
        "MIN_DEFAULT_EPOCHS = 1\n",
        "MAX_DEFAULT_EPOCHS = 25\n",
        "\n",
        "n_epochs = TARGET_EPOCHS\n",
        "n_train_examples = len(dataset)\n",
        "if n_train_examples * TARGET_EPOCHS < MIN_TARGET_EXAMPLES:\n",
        "    n_epochs = min(MAX_DEFAULT_EPOCHS, MIN_TARGET_EXAMPLES // n_train_examples)\n",
        "elif n_train_examples * TARGET_EPOCHS > MAX_TARGET_EXAMPLES:\n",
        "    n_epochs = max(MIN_DEFAULT_EPOCHS, MAX_TARGET_EXAMPLES // n_train_examples)\n",
        "\n",
        "n_billing_tokens_in_dataset = sum(min(MAX_TOKENS_PER_EXAMPLE, length) for length in convo_lens)\n",
        "print(f\"Dataset has ~{n_billing_tokens_in_dataset} tokens that will be charged for during training\")\n",
        "print(f\"By default, you'll train for {n_epochs} epochs on this dataset\")\n",
        "print(f\"By default, you'll be charged for ~{n_epochs * n_billing_tokens_in_dataset} tokens\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1imA9WZbDUN9"
      },
      "source": [
        "## 500k gpt-3.5-turbo training tokens = $4"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NGc6pwofCOxd"
      },
      "source": [
        "# let's start finetune the model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Lk-yHksuA_8H"
      },
      "outputs": [
        {
          "ename": "",
          "evalue": "",
          "output_type": "error",
          "traceback": [
            "\u001b[1;31m运行具有“c:\\Users\\Administrator\\AppData\\Local\\Programs\\Python\\Python310-32\\python.exe”的单元格需要ipykernel包。\n",
            "\u001b[1;31mRun the following command to install 'ipykernel' into the Python environment. \n",
            "\u001b[1;31mCommand: 'c:/Users/Administrator/AppData/Local/Programs/Python/Python310-32/python.exe -m pip install ipykernel -U --user --force-reinstall'"
          ]
        }
      ],
      "source": [
        "import json\n",
        "import openai\n",
        "import os\n",
        "import pandas as pd\n",
        "from pprint import pprint\n",
        "\n",
        "#OPENAI_API_KEY = os.getenv(\"OPENAI_API_KEY\", \"\")\n",
        "OPENAI_API_KEY = \"sess-7KZWK9vWwzg81K51QMbuP30wEA7OP7jo7OpCdIGw\"\n",
        "openai.api_key = OPENAI_API_KEY"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Rp5eOOROBceu"
      },
      "outputs": [
        {
          "ename": "",
          "evalue": "",
          "output_type": "error",
          "traceback": [
            "\u001b[1;31m运行具有“c:\\Users\\Administrator\\AppData\\Local\\Programs\\Python\\Python310-32\\python.exe”的单元格需要ipykernel包。\n",
            "\u001b[1;31mRun the following command to install 'ipykernel' into the Python environment. \n",
            "\u001b[1;31mCommand: 'c:/Users/Administrator/AppData/Local/Programs/Python/Python310-32/python.exe -m pip install ipykernel -U --user --force-reinstall'"
          ]
        }
      ],
      "source": [
        "training_file_name = \"/content/training_data.jsonl\"\n",
        "\n",
        "validation_file_name = \"/content/validation_data.jsonl\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TSX-bYSiCGdn",
        "outputId": "a2e4ee57-4af7-484d-b85f-4e425c512cca"
      },
      "outputs": [
        {
          "ename": "",
          "evalue": "",
          "output_type": "error",
          "traceback": [
            "\u001b[1;31m运行具有“c:\\Users\\Administrator\\AppData\\Local\\Programs\\Python\\Python310-32\\python.exe”的单元格需要ipykernel包。\n",
            "\u001b[1;31mRun the following command to install 'ipykernel' into the Python environment. \n",
            "\u001b[1;31mCommand: 'c:/Users/Administrator/AppData/Local/Programs/Python/Python310-32/python.exe -m pip install ipykernel -U --user --force-reinstall'"
          ]
        }
      ],
      "source": [
        "with open(training_file_name, \"rb\") as training_fd:\n",
        "    training_response = openai.files.create(\n",
        "        file=training_fd, purpose=\"fine-tune\"\n",
        "    )\n",
        "\n",
        "training_file_id = training_response.id\n",
        "\n",
        "with open(validation_file_name, \"rb\") as validation_fd:\n",
        "    validation_response = openai.files.create(\n",
        "        file=validation_fd, purpose=\"fine-tune\"\n",
        "    )\n",
        "validation_file_id = validation_response.id\n",
        "\n",
        "print(\"Training file ID:\", training_file_id)\n",
        "print(\"Validation file ID:\", validation_file_id)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Eo4pnsytCZNO"
      },
      "outputs": [
        {
          "ename": "",
          "evalue": "",
          "output_type": "error",
          "traceback": [
            "\u001b[1;31m运行具有“c:\\Users\\Administrator\\AppData\\Local\\Programs\\Python\\Python310-32\\python.exe”的单元格需要ipykernel包。\n",
            "\u001b[1;31mRun the following command to install 'ipykernel' into the Python environment. \n",
            "\u001b[1;31mCommand: 'c:/Users/Administrator/AppData/Local/Programs/Python/Python310-32/python.exe -m pip install ipykernel -U --user --force-reinstall'"
          ]
        }
      ],
      "source": [
        "response = openai.fine_tuning.jobs.create(\n",
        "    training_file=training_file_id,\n",
        "    validation_file=validation_file_id,\n",
        "    model=\"gpt-3.5-turbo\",\n",
        "    suffix=\"recipe-ner\",\n",
        ")\n",
        "\n",
        "job_id = response.id\n",
        "\n",
        "print(\"Job ID:\", response.id)\n",
        "print(\"Status:\", response.status)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "97J4ecFXENLu"
      },
      "outputs": [
        {
          "ename": "",
          "evalue": "",
          "output_type": "error",
          "traceback": [
            "\u001b[1;31m运行具有“c:\\Users\\Administrator\\AppData\\Local\\Programs\\Python\\Python310-32\\python.exe”的单元格需要ipykernel包。\n",
            "\u001b[1;31mRun the following command to install 'ipykernel' into the Python environment. \n",
            "\u001b[1;31mCommand: 'c:/Users/Administrator/AppData/Local/Programs/Python/Python310-32/python.exe -m pip install ipykernel -U --user --force-reinstall'"
          ]
        }
      ],
      "source": [
        "response = openai.fine_tuning.jobs.retrieve(job_id)\n",
        "\n",
        "print(\"Job ID:\", response.id)\n",
        "print(\"Status:\", response.status)\n",
        "print(\"Trained Tokens:\", response.trained_tokens)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "YqY4OM_wEQtv"
      },
      "outputs": [
        {
          "ename": "",
          "evalue": "",
          "output_type": "error",
          "traceback": [
            "\u001b[1;31m运行具有“c:\\Users\\Administrator\\AppData\\Local\\Programs\\Python\\Python310-32\\python.exe”的单元格需要ipykernel包。\n",
            "\u001b[1;31mRun the following command to install 'ipykernel' into the Python environment. \n",
            "\u001b[1;31mCommand: 'c:/Users/Administrator/AppData/Local/Programs/Python/Python310-32/python.exe -m pip install ipykernel -U --user --force-reinstall'"
          ]
        }
      ],
      "source": [
        "response = openai.fine_tuning.jobs.list_events(job_id)\n",
        "\n",
        "events = response.data\n",
        "events.reverse()\n",
        "\n",
        "for event in events:\n",
        "    print(event.message)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ncoIvuRoEURn"
      },
      "outputs": [
        {
          "ename": "",
          "evalue": "",
          "output_type": "error",
          "traceback": [
            "\u001b[1;31m运行具有“c:\\Users\\Administrator\\AppData\\Local\\Programs\\Python\\Python310-32\\python.exe”的单元格需要ipykernel包。\n",
            "\u001b[1;31mRun the following command to install 'ipykernel' into the Python environment. \n",
            "\u001b[1;31mCommand: 'c:/Users/Administrator/AppData/Local/Programs/Python/Python310-32/python.exe -m pip install ipykernel -U --user --force-reinstall'"
          ]
        }
      ],
      "source": [
        "response = openai.fine_tuning.jobs.retrieve(job_id)\n",
        "fine_tuned_model_id = response.fine_tuned_model\n",
        "\n",
        "if fine_tuned_model_id is None:\n",
        "    raise RuntimeError(\"Fine-tuned model ID not found. Your job has likely not been completed yet.\")\n",
        "\n",
        "print(\"Fine-tuned model ID:\", fine_tuned_model_id)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "71DJ00EFEbit"
      },
      "outputs": [
        {
          "ename": "",
          "evalue": "",
          "output_type": "error",
          "traceback": [
            "\u001b[1;31m运行具有“c:\\Users\\Administrator\\AppData\\Local\\Programs\\Python\\Python310-32\\python.exe”的单元格需要ipykernel包。\n",
            "\u001b[1;31mRun the following command to install 'ipykernel' into the Python environment. \n",
            "\u001b[1;31mCommand: 'c:/Users/Administrator/AppData/Local/Programs/Python/Python310-32/python.exe -m pip install ipykernel -U --user --force-reinstall'"
          ]
        }
      ],
      "source": [
        "test_df = recipe_df.loc[201:300]\n",
        "test_row = test_df.iloc[0]\n",
        "test_messages = []\n",
        "test_messages.append({\"role\": \"system\", \"content\": system_message})\n",
        "user_message = create_user_message(test_row)\n",
        "test_messages.append({\"role\": \"user\", \"content\": create_user_message(test_row)})\n",
        "\n",
        "pprint(test_messages)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "mRslF4nfEdEe"
      },
      "outputs": [
        {
          "ename": "",
          "evalue": "",
          "output_type": "error",
          "traceback": [
            "\u001b[1;31m运行具有“c:\\Users\\Administrator\\AppData\\Local\\Programs\\Python\\Python310-32\\python.exe”的单元格需要ipykernel包。\n",
            "\u001b[1;31mRun the following command to install 'ipykernel' into the Python environment. \n",
            "\u001b[1;31mCommand: 'c:/Users/Administrator/AppData/Local/Programs/Python/Python310-32/python.exe -m pip install ipykernel -U --user --force-reinstall'"
          ]
        }
      ],
      "source": [
        "response = openai.chat.completions.create(\n",
        "    model=fine_tuned_model_id, messages=test_messages, temperature=0, max_tokens=500\n",
        ")\n",
        "print(response.choices[0].message.content)"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "toc_visible": true
    },
    "kernelspec": {
      "display_name": "chatglm3-demo",
      "language": "python",
      "name": "chatglm3-demo"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.11"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
